<h1>Homework: Web Crawling</h1>
<h2>Objective</h2>
<br>In this assignment, you will work with a simple web crawler to measure aspects of a crawl, study the characteristics of the crawl, download web pages from the crawl and gather webpage metadata, all from pre-selected news websites.
<h2>Crawling</h2>
<br>
<br>Your task is to configure and compile the crawler and then have it crawl a news website. In the interest of distributing the load evenly and not overloading the news servers, we have pre-assigned the news sites to be crawled according to your USC ID number, given in the table below.
<br>The maximum pages to fetch can be set in crawler4j and it should be set to 20,000 to ensure a reasonable execution time for this exercise. Also, maximum depth should be set to 16 to ensure that we limit the crawling.
<br>You should crawl only the news websites assigned to you, and your crawler should be configured so that it does not visit pages outside of the given news website!
<br> Exercise pdf contains more information
